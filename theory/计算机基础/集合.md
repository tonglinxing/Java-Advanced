- #### Java集合框架

**数据结构考点**

1. 数组和链表的区别
2. 链表的操作，如反转，链表环路检测，双向链表，循环链表相关操作
3. 队列，栈的应用
4. 二叉树的遍历方式及其递归和非递归的实现
5. 红黑树的旋转

**算法考点**

1. 内部排序：如递归排序、交换排序(冒泡、快排)、选择排序、插入排序
2. 外部排序：应掌握如何利用有限的内存配合海量的外部存储来处理超大数据集

考点扩展：

1. 哪些排序是不稳定的，稳定意味着什么
2. 不同数据集，各种排序最好或最差的情况
3. 如何优化算法

- **HashMap、HashTable、ConcurrentHashMap**

**HashMap：**(Java 8 以前)数组+链表（拉链法）(Java8 以后)数组+链表+红黑树

put方法的逻辑：

1. 若HashMap未被初始化，则进行初始化操作
2. 对Key求Hash值，根据Hash值计算下标
3. 若未发生碰撞，则直接放入桶中
4. 若发生碰撞，则以链表的方式链接到后面
5. 若链表长度超过阀值(默认为8)且HashMap元素超过最低树化容量(默认为64)，则将链表转成红黑树
6. 若节点已经存在，则用新值替换旧值
7. 若桶满了(默认容量16*扩容因子0.75), 就需要resize(扩容两倍后重排)

如何有效减少碰撞：

1. 扰动函数：促使元素位置分布均匀，减少碰撞几率
2. 使用final对象，并采用合适的equals()和hashCode()方法

扩容的问题：

1. 多线程环境下，调整大小会存在条件竞争，容易造成死锁
2. rehashing是一个比较耗时的过程（即从原来的HashMap移植进扩容后的新HashMap中）

**Hashtable**

1. 早期Java类库提供的哈希表的实现
2. 线程安全：涉及到修改Hashtable的方法都使用synchronized修饰
3. 串行化的方式运行，性能较差

如何优化Hashtable：细化锁粒度

**ConcurrentHashMap**

早期版本：通过分段锁Segment实现

当前版本：CAS+synchronized使锁更细化（数据结构和HashMap1.8一样）

put方法的逻辑：

1. 判断Node[]数组是否初始化，没有则进行初始化操作

2. 通过hash定位数组的索引坐标是否有Node节点，如果没有则使用CAS进行添加（链表的头节点），添加失败则进入下次循环

3. 检查到内部正在扩容，就帮助它一块扩容

4. 如果索引坐标已经有值即f!=null，则使用synchronized锁住f元素（链表/红黑二叉树的头元素）

   4.1 如果是Node（链表结构）则执行链表的添加操作

   4.2 如果是TreeNode（树形结构）则执行树添加操作

5. 判断链表长度是否已经达到临界值，当节点数超过这个值需要将链表转换为树结构

ConcurrnetHashMap总结：

1. 首先使用无锁操作CAS插入头节点，失败则循环重试
2. 若头节点已存在，则尝试获取头节点的同步锁，再进行操作

ConcurrentHashMap别的需要注意的点：

1. size()方法和mappingCount()方法的异同，两者计算是否准确？
2. 多线程环境下如何进行扩容？

**三者的区别**

1. HashMap线程不安全，数组+链表+红黑树
2. Hashtable线程安全，锁住整个对象，数组+链表
3. ConcurrentHashMap线程安全：CAS+同步锁，数组+链表+红黑树
4. HashMap的key，value均可为null，而其他两个不支持

---

